"""Vertex AI post-processing module for transcript formatting."""

import datetime
from typing import Optional

from ..config import settings, VertexAIModels
from ..utils.colors import Colors


class VertexPostProcessor:
    """Vertex AI (Gemini) post-processor for script-style formatting."""
    
    def __init__(self):
        self.project_id = settings.vertex_project_id
    
    def process(self, transcript_text: str, video_title: str = "", vertex_ai_model: str = "") -> Optional[str]:
        """
        Post-process transcript using Vertex AI (Gemini) for script formatting.
        
        Args:
            transcript_text: Original transcript text
            video_title: Video title
            
        Returns:
            Formatted script text or None on error
        """
        print(Colors.BLUE + "\nü§ñ Vertex AI ut√≥feldolgoz√°s ind√≠t√°sa..." + Colors.ENDC)
        
        try:
            import vertexai
            from vertexai.generative_models import GenerativeModel, GenerationConfig
            
            print(Colors.CYAN + f"   ‚îú‚îÄ Project: {self.project_id}" + Colors.ENDC)
            
            # Determine which models to try
            if vertex_ai_model and vertex_ai_model != VertexAIModels.AUTO_DETECT:
                # User specified a model, try only that one first
                models_to_try = [vertex_ai_model] + VertexAIModels.get_auto_detect_order()
                print(Colors.CYAN + f"   ‚îú‚îÄ Kiv√°lasztott modell: {vertex_ai_model}" + Colors.ENDC)
            else:
                # Auto-detect mode
                models_to_try = VertexAIModels.get_auto_detect_order()
                print(Colors.CYAN + "   ‚îú‚îÄ Automatikus modell kiv√°laszt√°s" + Colors.ENDC)
            
            # Try different regions
            regions = ["us-central1", "us-east1", "us-west1", "europe-west4"]
            
            model = None
            successful_config = None
            
            for region in regions:
                for model_name in models_to_try:
                    try:
                        print(Colors.CYAN + f"   ‚îú‚îÄ Pr√≥b√°lkoz√°s: {model_name} @ {region}" + Colors.ENDC)
                        
                        # Initialize Vertex AI with current region
                        vertexai.init(project=self.project_id, location=region)
                        model = GenerativeModel(model_name)
                        
                        successful_config = (model_name, region)
                        print(Colors.GREEN + f"   ‚úì Sikeres kapcsolat: {model_name} @ {region}" + Colors.ENDC)
                        break
                        
                    except Exception as e:
                        print(Colors.WARNING + f"   ‚úó {model_name} @ {region}: {str(e)[:100]}..." + Colors.ENDC)
                        continue
                
                if successful_config:
                    break
            
            if not successful_config:
                raise Exception("Nem siker√ºlt kapcsol√≥dni egyetlen Gemini modellhez sem")
                
            print(Colors.CYAN + "   ‚îî‚îÄ Prompt k√ºld√©se..." + Colors.ENDC)
            
            # Create formatting prompt
            prompt = self._build_formatting_prompt(transcript_text)
            
            # Call Gemini API
            print(Colors.BLUE + "   ‚è≥ Gemini v√°lasz√°ra v√°runk..." + Colors.ENDC)
            
            response = model.generate_content(
                prompt,
                generation_config=GenerationConfig(
                    temperature=0.3,  # Low temperature for consistent formatting
                    max_output_tokens=8192,
                    top_p=0.8,
                )
            )
            
            formatted_text = response.text
            
            # Build final result with header
            final_text = self._build_final_result(formatted_text, video_title, transcript_text, successful_config[0])
            
            print(Colors.GREEN + f"   ‚úì Vertex AI form√°z√°s k√©sz ({successful_config[0]}): {len(formatted_text.split())} sz√≥" + Colors.ENDC)
            
            return final_text
            
        except ImportError:
            print(Colors.WARNING + "‚ö† Vertex AI k√∂nyvt√°r nincs telep√≠tve!" + Colors.ENDC)
            print(Colors.WARNING + "   Telep√≠tsd: pip install google-cloud-aiplatform" + Colors.ENDC)
            return self._fallback_processing(transcript_text, video_title)
        except Exception as e:
            print(Colors.FAIL + f"‚úó Vertex AI hiba: {e}" + Colors.ENDC)
            print(Colors.WARNING + f"   R√©szletek: {str(e)}" + Colors.ENDC)
            print(Colors.CYAN + "   üîÑ Fallback form√°z√°s alkalmaz√°sa..." + Colors.ENDC)
            return self._fallback_processing(transcript_text, video_title)
    
    def _fallback_processing(self, transcript_text: str, video_title: str = "") -> str:
        """
        Fallback processing when Vertex AI is unavailable.
        Apply basic formatting without AI processing.
        """
        print(Colors.CYAN + "   ‚îú‚îÄ Egyszer≈± form√°z√°s alkalmaz√°sa" + Colors.ENDC)
        
        # Add header and basic formatting
        lines = transcript_text.split('\n')
        formatted_lines = []
        
        for line in lines:
            if line.strip():
                # Add proper capitalization and punctuation
                formatted_line = line.strip()
                if formatted_line and not formatted_line[0].isupper():
                    formatted_line = formatted_line[0].upper() + formatted_line[1:]
                if formatted_line and not formatted_line.endswith(('.', '!', '?')):
                    formatted_line += '.'
                formatted_lines.append(formatted_line)
            else:
                formatted_lines.append('')
        
        # Build final result
        formatted_text = '\n'.join(formatted_lines)
        final_text = self._build_final_result(formatted_text, video_title, transcript_text, "Fallback Format")
        
        print(Colors.GREEN + "   ‚úì Fallback form√°z√°s k√©sz" + Colors.ENDC)
        return final_text
    
    def _build_formatting_prompt(self, transcript_text: str) -> str:
        """Build the formatting prompt for Gemini."""
        # Limit transcript to first 5000 characters due to prompt limits
        limited_transcript = transcript_text[:5000]
        
        prompt = f"""Form√°zd √°t ezt a YouTube vide√≥ √°tiratot professzion√°lis SCRIPT/FELIRAT st√≠lus√∫ra!

EREDETI √ÅTIRAT (Google Speech API):
{limited_transcript}

FORM√ÅZ√ÅSI SZAB√ÅLYOK:
1. MINDEN mondatot/tagmondatot k√ºl√∂n sorba, id≈ëb√©lyeggel [HH:MM:SS] form√°tumban
2. Maximum 12-15 sz√≥ soronk√©nt (√°tlag besz√©dtemp√≥: 140 sz√≥/perc)
3. Mondatv√©gekn√©l (.!?) MINDIG √∫j sor
4. Minden jelent≈ës sz√ºnetet jel√∂lj k√ºl√∂n sorban id≈ëb√©lyeggel:
   [0:XX:XX] [r√∂vid sz√ºnet] = kb 0.5-1s csend
   [0:XX:XX] [leveg≈ëv√©tel] = kb 1-2s sz√ºnet
   [0:XX:XX] [hossz√∫ sz√ºnet] = kb 2-3s sz√ºnet
   [0:XX:XX] [T√âMAV√ÅLT√ÅS] = 3s+ sz√ºnet vagy √∫j t√©ma
5. Term√©szetes besz√©dritmus k√∂vet√©se
6. K√∂t≈ëszavakn√°l (√©s, de, hogy, mert, hiszen) t√∂rj sort ha m√°r 8+ sz√≥ van
7. Vessz≈ëkn√©l t√∂rj sort ha a mondat m√°r hossz√∫
8. Becs√ºld meg re√°lisan az id≈ëb√©lyegeket (140 sz√≥/perc = kb 2.3 sz√≥/mp)

P√âLDA KIMENETI FORM√ÅTUM:
[0:00:00] Sziasztok, szeretettel k√∂sz√∂ntelek benneteket.
[0:00:03] [leveg≈ëv√©tel]
[0:00:04] Hoztam nektek a mai napra is egy √ºzenetet,
[0:00:07] egy √°ltal√°nos k√°rtya olvas√°st.
[0:00:09] [r√∂vid sz√ºnet]
[0:00:10] K√°rtya kirak√°s, itt l√°tj√°tok az asztalomon
[0:00:13] az univerzumnak az √ºzenet√©vel kezden√©m,
[0:00:16] [leveg≈ëv√©tel]
[0:00:17] ami azt mondja √©s azt √ºzeni nektek,
[0:00:20] hogy j√≥ lenne, hogyha √°t adn√°tok magatokat
[0:00:23] egy n√°latok hatalmasabb Er≈ënek.
[0:00:26] [hossz√∫ sz√ºnet]
[0:00:28] Az azt jelenti, hogy √°tadom magam
[0:00:31] egy n√°lam hatalmasabb Er≈ënek.

FONTOS: 
- Legal√°bb 100-150 sor legyen a v√©geredm√©ny
- Minden sz√ºnetet jel√∂lj ahol √©rzed a besz√©dben
- A mondatok legyenek term√©szetesek, ne t√∂rj rossz helyen
- Az id≈ëb√©lyegek legyenek re√°lisak

FORM√ÅZOTT SCRIPT:"""
        
        return prompt
    
    def _build_final_result(self, formatted_text: str, video_title: str, 
                          original_transcript: str, model_name: str = "Gemini") -> str:
        """Build final result with header and statistics."""
        final_text = f"üìπ Vide√≥: {video_title}\n"
        final_text += f"üìÖ Feldolgozva: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        final_text += f"ü§ñ Ut√≥feldolgoz√°s: Vertex AI ({model_name})\n"
        final_text += "=" * 70 + "\n\n"
        final_text += formatted_text
        
        # Add note if transcript was truncated
        if len(original_transcript) > 5000:
            final_text += f"\n\n[FIGYELEM: A teljes √°tirat {len(original_transcript)} karakter, csak az els≈ë 5000 lett form√°zva]"
        
        # Calculate statistics
        lines = formatted_text.split('\n')
        word_count = len(formatted_text.split())
        pause_count = formatted_text.count('[') - formatted_text.count('[0:')
        
        final_text += f"\n\n{'='*70}\n"
        final_text += f"üìä Script statisztika (AI form√°z√°s):\n"
        final_text += f"   ‚Ä¢ Sorok sz√°ma: {len(lines)}\n"
        final_text += f"   ‚Ä¢ √ñsszes sz√≥: {word_count}\n"
        final_text += f"   ‚Ä¢ Detekt√°lt sz√ºnetek: {pause_count}\n"
        final_text += f"   ‚Ä¢ √Åtlagos sorhossz: {word_count/len(lines) if lines else 0:.1f} sz√≥\n"
        
        return final_text